{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/chessgpt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import einops\n",
    "import wandb\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import random\n",
    "from IPython.display import display\n",
    "import wandb\n",
    "from jaxtyping import Float, Int, Bool, Shaped, jaxtyped\n",
    "from typing import Union, Optional, Tuple, Callable, Dict\n",
    "import typeguard\n",
    "from functools import partial\n",
    "import copy\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import HookedRootModule, HookPoint\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "from tqdm.notebook import tqdm\n",
    "from dataclasses import dataclass\n",
    "from rich import print as rprint\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import circuits.eval_sae_as_classifier as eval_sae\n",
    "import circuits.analysis as analysis\n",
    "import circuits.eval_board_reconstruction as eval_board_reconstruction\n",
    "import circuits.get_eval_results as get_eval_results\n",
    "import circuits.f1_analysis as f1_analysis\n",
    "import circuits.utils as utils\n",
    "import circuits.pipeline_config as pipeline_config\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "import chess_utils\n",
    "\n",
    "import pickle\n",
    "with open('meta.pkl', 'rb') as picklefile:\n",
    "    meta = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Othello: False\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "autoencoder_group_path = \"/root/chessgpt_git/chessgpt_git/SAE_BoardGameEval/autoencoders/testing_chess/\"\n",
    "autoencoder_path = \"/root/chessgpt_git/chessgpt_git/SAE_BoardGameEval/autoencoders/testing_chess/trainer4/\"\n",
    "\n",
    "othello = eval_sae.check_if_autoencoder_is_othello(autoencoder_group_path)\n",
    "config = pipeline_config.Config()\n",
    "\n",
    "# These both significantly reduce peak GPU memory usage\n",
    "config.batch_size = 5\n",
    "config.analysis_on_cpu = True\n",
    "\n",
    "# Precompute will create both datasets and save them as pickle files\n",
    "# If precompute == False, it creates the dataset on the fly\n",
    "# This is far slower when evaluating multiple SAEs, but for an exploratory run it is fine\n",
    "config.precompute = False\n",
    "\n",
    "config.eval_results_n_inputs = 1000\n",
    "config.eval_sae_n_inputs = 1000\n",
    "config.board_reconstruction_n_inputs = 1000\n",
    "\n",
    "# Once you have ran the analysis, you can set this to False and it will load the saved results\n",
    "config.run_analysis = False\n",
    "config.run_board_reconstruction = False\n",
    "config.run_eval_sae = False\n",
    "config.run_eval_results = False\n",
    "\n",
    "# If you want to save the results of the analysis\n",
    "config.save_results = True\n",
    "config.save_feature_labels = True\n",
    "\n",
    "print(f\"Is Othello: {othello}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing_functions = eval_sae.get_recommended_indexing_functions(othello)\n",
    "indexing_function = indexing_functions[0]\n",
    "\n",
    "expected_aggregation_output_location = eval_sae.get_output_location(\n",
    "    autoencoder_path,\n",
    "    n_inputs=config.eval_sae_n_inputs,\n",
    "    indexing_function=indexing_function,\n",
    ")\n",
    "\n",
    "analysis_device = device\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "expected_feature_labels_output_location = expected_aggregation_output_location.replace(\n",
    "    \"results.pkl\", \"feature_labels.pkl\"\n",
    ")\n",
    "\n",
    "with open(expected_feature_labels_output_location, \"rb\") as f:\n",
    "    feature_labels = pickle.load(f)\n",
    "feature_labels = utils.to_device(feature_labels, analysis_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rc_to_square_notation(row, col):\n",
    "    letters = \"ABCDEFGH\"\n",
    "    number = row + 1\n",
    "    letter = letters[col]\n",
    "    return f\"{letter}{number}\"\n",
    "\n",
    "def plot_board(board_RR: torch.Tensor, title: str = \"Board\", png_filename: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    Plots an 8x8 board with the value of the maximum square displayed in red text to two decimal places.\n",
    "\n",
    "    Args:\n",
    "        board_RR (torch.Tensor): A 2D tensor of shape (8, 8) with values from 0 to 1.\n",
    "        title (str): Title of the plot.\n",
    "    \"\"\"\n",
    "    assert board_RR.shape == (8, 8), \"board_RR must be of shape 8x8\"\n",
    "\n",
    "    # Flip the board vertically\n",
    "    board_RR = torch.flip(board_RR, [0])\n",
    "\n",
    "    plt.imshow(board_RR, cmap='gray_r', interpolation='none', vmin=0, vmax=1)\n",
    "    plt.colorbar()  # Adds a colorbar to help identify the values\n",
    "    plt.title(title)\n",
    "\n",
    "    # Set labels for columns (A-H)\n",
    "    plt.xticks(range(8), ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])\n",
    "\n",
    "    # Set labels for rows (1-8)\n",
    "    plt.yticks(range(8), range(8, 0, -1))\n",
    "\n",
    "    # Add gridlines mimicking a chess board\n",
    "    # plt.grid(True, color='black', linewidth=1, linestyle='-', alpha=0.5)\n",
    "    # plt.tick_params(bottom=False, left=False, labelbottom=True, labelleft=True)\n",
    "\n",
    "    # Offset gridlines by 0.5 in x and y\n",
    "    plt.gca().set_xticks([x - 0.5 for x in range(1, 9)], minor=True)\n",
    "    plt.gca().set_yticks([y - 0.51 for y in range(1, 9)], minor=True)\n",
    "    plt.grid(True, which='minor', color='black', linewidth=1, linestyle='-', alpha=0.5)\n",
    "\n",
    "    # Find the maximum value and its position\n",
    "    max_value, max_pos = torch.max(board_RR), torch.argmax(board_RR)\n",
    "    max_i, max_j = torch.div(max_pos, 8, rounding_mode='floor'), max_pos % 8\n",
    "\n",
    "    # Display the maximum value in red text at the corresponding position\n",
    "    plt.text(max_j, max_i, f\"{max_value:.0%}\", color='red', ha='center', va='center', fontsize=12)\n",
    "\n",
    "    if png_filename is not None:\n",
    "        plt.savefig(png_filename)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "num_to_class = {0: \"Black King\", 1: \"Black Queen\", 2: \"Black Rook\", 3: \"Black Bishop\", 4: \"Black Knight\", 5: \"Black Pawn\",\n",
    "                6: \"Blank\", 7: \"White Pawn\", 8: \"White Knight\", 9: \"White Bishop\", 10: \"White Rook\", 11: \"White Queen\", 12: \"White King\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board state feature labels: torch.Size([11, 3914, 8, 8, 13])\n",
      "Feature 1 has 1 classified squares\n",
      "Feature 44 has 1 classified squares\n",
      "Feature 52 has 2 classified squares\n",
      "Feature 59 has 1 classified squares\n",
      "Feature 66 has 1 classified squares\n",
      "Feature 70 has 1 classified squares\n",
      "Feature 75 has 2 classified squares\n",
      "Feature 107 has 1 classified squares\n",
      "Feature 109 has 1 classified squares\n",
      "Feature 121 has 1 classified squares\n",
      "Feature 127 has 1 classified squares\n",
      "Feature 134 has 1 classified squares\n",
      "Feature 143 has 1 classified squares\n",
      "Feature 146 has 4 classified squares\n",
      "Feature 150 has 1 classified squares\n",
      "Feature 152 has 1 classified squares\n",
      "Feature 165 has 2 classified squares\n",
      "Feature 172 has 1 classified squares\n",
      "\n",
      "Feature 172 has 1 classified squares\n",
      "Classified squares as tensors: (tensor([2], device='cuda:0'), tensor([5], device='cuda:0'), tensor([8], device='cuda:0'))\n",
      "\n",
      "Classified squares for feature 172 at threshold 2:\n",
      "F3 White Knight\n"
     ]
    }
   ],
   "source": [
    "function_of_interest = \"board_to_piece_masked_blank_and_initial_state\"\n",
    "\n",
    "board_state_feature_labels_TFRRC = feature_labels[function_of_interest]\n",
    "print(f\"Board state feature labels: {board_state_feature_labels_TFRRC.shape}\")\n",
    "threshold = 2\n",
    "\n",
    "board_state_feature_labels_FRRC = board_state_feature_labels_TFRRC[threshold]\n",
    "board_state_counts_F = einops.reduce(board_state_feature_labels_FRRC, \"F R1 R2 C -> F\", \"sum\")\n",
    "\n",
    "max_features = 175\n",
    "demo_idx = 0\n",
    "for i in range(max_features):\n",
    "    if board_state_counts_F[i] > 0:\n",
    "        print(f\"Feature {i} has {board_state_counts_F[i]} classified squares\")\n",
    "        demo_idx = i\n",
    "\n",
    "demo_feature_labels_RRC = board_state_feature_labels_FRRC[demo_idx]\n",
    "print(f\"\\nFeature {demo_idx} has {board_state_counts_F[demo_idx].sum().item()} classified squares\")\n",
    "\n",
    "classified_squares = torch.where(demo_feature_labels_RRC == 1)\n",
    "print(f\"Classified squares as tensors: {classified_squares}\")\n",
    "\n",
    "row, column, classes = classified_squares\n",
    "\n",
    "print(f\"\\nClassified squares for feature {demo_idx} at threshold {threshold}:\")\n",
    "for i in range(row.shape[0]):\n",
    "    print(rc_to_square_notation(row[i].item(), column[i].item()), num_to_class[classes[i].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_aggregation_output_location = eval_sae.get_output_location(\n",
    "    autoencoder_path,\n",
    "    n_inputs=config.eval_sae_n_inputs,\n",
    "    indexing_function=indexing_function,\n",
    ")\n",
    "\n",
    "\n",
    "with open(expected_aggregation_output_location, \"rb\") as f:\n",
    "    aggregation_results = pickle.load(f)\n",
    "aggregation_results = utils.to_device(aggregation_results, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_functions = config.chess_functions\n",
    "formatted_results = analysis.add_off_tracker(aggregation_results, custom_functions, analysis_device)\n",
    "\n",
    "formatted_results = analysis.normalize_tracker(\n",
    "    formatted_results,\n",
    "    \"on\",\n",
    "    custom_functions,\n",
    "    analysis_device,\n",
    ")\n",
    "\n",
    "formatted_results = analysis.normalize_tracker(\n",
    "    formatted_results,\n",
    "    \"off\",\n",
    "    custom_functions,\n",
    "    analysis_device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_results = analysis.add_off_tracker(aggregation_results, custom_functions, analysis_device)\n",
    "\n",
    "formatted_results = analysis.normalize_tracker(\n",
    "    formatted_results,\n",
    "    \"on\",\n",
    "    custom_functions,\n",
    "    analysis_device,\n",
    ")\n",
    "\n",
    "formatted_results = analysis.normalize_tracker(\n",
    "    formatted_results,\n",
    "    \"off\",\n",
    "    custom_functions,\n",
    "    analysis_device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 156,  215,  390,  583,  670,  709,  727, 1155, 1327, 1536, 1596, 1730,\n",
       "        1777, 1797, 1881, 1957, 2154, 2201, 2276, 2283, 2424, 2485, 2674, 2835,\n",
       "        3003, 3037, 3109, 3368, 3649, 3737], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_latent_indices = (formatted_results['board_to_check_state']['on_normalized'][2] > 0.999).nonzero()[:, 0]\n",
    "chess_latent_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 3914, 1, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_results['board_to_check_state']['on_normalized'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 167,  228,  410,  614,  706,  746,  765, 1218, 1396, 1610, 1673, 1810,\n",
       "        1858, 1878, 1969, 2048, 2252, 2303, 2381, 2388, 2533, 2595, 2794, 2960,\n",
       "        3133, 3168, 3240, 3517, 3814, 3911], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregation_results['alive_features'][chess_latent_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['on', 'all', 'off', 'on_normalized', 'off_normalized'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregation_results['board_to_check_state'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcircuits\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval_sae_as_classifier\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prep_data_ae_buffer_and_model\n\u001b[1;32m      2\u001b[0m data, ae_bundle, pgn_strings_bL, encoded_inputs_bL \u001b[38;5;241m=\u001b[39m prep_data_ae_buffer_and_model(\n\u001b[1;32m      3\u001b[0m         autoencoder_path,\n\u001b[0;32m----> 4\u001b[0m         \u001b[43mbatch_size\u001b[49m,\n\u001b[1;32m      5\u001b[0m         data,\n\u001b[1;32m      6\u001b[0m         device,\n\u001b[1;32m      7\u001b[0m         n_inputs,\n\u001b[1;32m      8\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "from circuits.eval_sae_as_classifier import prep_data_ae_buffer_and_model\n",
    "data, ae_bundle, pgn_strings_bL, encoded_inputs_bL = prep_data_ae_buffer_and_model(\n",
    "        autoencoder_path,\n",
    "        32,\n",
    "        data,\n",
    "        device,\n",
    "        n_inputs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chessgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
