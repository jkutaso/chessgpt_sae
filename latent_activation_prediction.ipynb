{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import einops\n",
    "import wandb\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import random\n",
    "from IPython.display import display\n",
    "import wandb\n",
    "from jaxtyping import Float, Int, Bool, Shaped, jaxtyped\n",
    "from typing import Union, Optional, Tuple, Callable, Dict\n",
    "from collections import Counter\n",
    "import typeguard\n",
    "from functools import partial\n",
    "import copy\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import HookedRootModule, HookPoint\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "from tqdm.notebook import tqdm\n",
    "from dataclasses import dataclass\n",
    "from rich import print as rprint\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import circuits.eval_sae_as_classifier as eval_sae\n",
    "import circuits.analysis as analysis\n",
    "import circuits.eval_board_reconstruction as eval_board_reconstruction\n",
    "import circuits.get_eval_results as get_eval_results\n",
    "import circuits.f1_analysis as f1_analysis\n",
    "import circuits.utils as utils\n",
    "import circuits.pipeline_config as pipeline_config\n",
    "from circuits.dictionary_learning.dictionary import AutoEncoder, GatedAutoEncoder, AutoEncoderNew\n",
    "import common\n",
    "import chess_utils\n",
    "import chess\n",
    "#from plotly_utils import imshow\n",
    "#from neel_plotly import scatter, line\n",
    "\n",
    "\n",
    "\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "import pickle\n",
    "with open('meta.pkl', 'rb') as picklefile:\n",
    "    meta = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/chessgpt/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading statistics aggregation dataset\n"
     ]
    }
   ],
   "source": [
    "autoencoder = common.load_autoencoder(device)\n",
    "model = common.load_model(device)\n",
    "dataset = common.get_dataset(device)\n",
    "TRAIN_TEST_GAME_SPLIT = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs_tensor = t.stack([t.tensor(x) for x in dataset['encoded_inputs']]).to(device)\n",
    "is_check = dataset['board_to_check_state'].squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_results = common.get_aggregation_results(1000)\n",
    "formatted_results = common.get_formatted_results(aggregation_results)\n",
    "features_for_check_state = common.get_true_feature_indices(formatted_results, \"board_to_check_state\")\n",
    "features_for_check_state = features_for_check_state.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_sae_activations = []\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        encoded_activations = autoencoder.encode(output[0]) # batch_size x len_seq x n_features_sae\n",
    "        collapsed = (encoded_activations.max(dim=0).values.max(dim=0).values)\n",
    "        max_sae_activations.append(collapsed.unsqueeze(0))\n",
    "    return hook\n",
    "\n",
    "t.set_grad_enabled(False)\n",
    "activation_handle = model.transformer.h[5].register_forward_hook(get_activation(f\"resid_stream_{5}\"))\n",
    "num_batches = 100\n",
    "batch_size = len(encoded_inputs_tensor) // num_batches\n",
    "if device == 'cpu':\n",
    "    num_batches = 1\n",
    "    batch_size = 1\n",
    "    \n",
    "for i in range(num_batches):\n",
    "    model(encoded_inputs_tensor[i*batch_size:(i+1)*batch_size])\n",
    "    t.cuda.empty_cache()\n",
    "activation_handle.remove()\n",
    "\n",
    "max_activations = t.concat(max_sae_activations).max(dim=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_sae_activations = []\n",
    "def get_activation(name, relevant_features):\n",
    "    def hook(model, input, output):\n",
    "        encoded_activations = autoencoder.encode(output[0]) # batch_size x len_seq x n_features_sae\n",
    "        relevant_sae_activations.append(encoded_activations[:, :, features_for_check_state])\n",
    "    return hook\n",
    "\n",
    "t.set_grad_enabled(False)\n",
    "activation_handle = model.transformer.h[5].register_forward_hook(get_activation(f\"resid_stream_{5}\", features_for_check_state))\n",
    "num_batches = 100\n",
    "batch_size = len(encoded_inputs_tensor) // num_batches\n",
    "if device == 'cpu':\n",
    "    num_batches = 1\n",
    "    batch_size = 1\n",
    "for i in range(num_batches):\n",
    "    model(encoded_inputs_tensor[i*batch_size:(i+1)*batch_size])\n",
    "    t.cuda.empty_cache()\n",
    "activation_handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5000, 256, 30]), torch.Size([5000, 256]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_relevant_sae_activations = t.concat(relevant_sae_activations, dim=0)\n",
    "is_this_a_dot = (encoded_inputs_tensor == meta['stoi']['.']).to(device)\n",
    "all_relevant_sae_activations.shape, is_this_a_dot.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_activations_for_dots = all_relevant_sae_activations * is_this_a_dot.unsqueeze(-1)\n",
    "inverse_sae_activations_for_dots = (max_activations[features_for_check_state] - all_relevant_sae_activations) * is_this_a_dot.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5000, 256, 30]), torch.Size([4096]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_activations_for_dots.shape, max_activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4115, 3]), torch.Size([3608581, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.4\n",
    "indices_of_high_activation = (sae_activations_for_dots > threshold*max_activations[features_for_check_state]).nonzero()\n",
    "indices_of_low_activation = (inverse_sae_activations_for_dots > 0.99*max_activations[features_for_check_state]).nonzero()\n",
    "indices_of_high_activation.shape, indices_of_low_activation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 20,  21,  22,  28,  29,  30,  31,  32,  33,  36,  37,  38,  39,  40,\n",
       "          41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
       "          55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
       "          69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
       "          83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,\n",
       "          97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
       "         111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
       "         125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
       "         139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
       "         153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166,\n",
       "         167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180,\n",
       "         181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "         195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
       "         209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
       "         223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
       "         237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
       "         251, 252, 253, 254, 255], device='cuda:0'),\n",
       " tensor([ 167,  228,  410,  614,  706,  746,  765, 1218, 1396, 1610, 1673, 1810,\n",
       "         1858, 1878, 1969, 2048, 2252, 2303, 2381, 2388, 2533, 2595, 2794, 2960,\n",
       "         3133, 3168, 3240, 3517, 3814, 3911], device='cuda:0'))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_of_high_activation[:, 1].unique(), features_for_check_state.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well do we do if we just use 'is_check' as a classifier for some random feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9747899159663865\n",
      "Precision: 0.4375\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6086956521739131\n"
     ]
    }
   ],
   "source": [
    "def is_check(board):\n",
    "    return board.is_check()\n",
    "\n",
    "i = 5\n",
    "boards_to_show = 3\n",
    "low_to_high_data_points = 50\n",
    "\n",
    "def get_last_space_index(game_string):\n",
    "    for i in range(len(game_string)-1, -1, -1):\n",
    "        if game_string[i] == ' ':\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def get_activation_data_for_feature(i, low_to_high_data_points, use_train_data):\n",
    "    if use_train_data:\n",
    "        filtered_indices_of_high_activation = indices_of_high_activation[indices_of_high_activation[:, 0] < TRAIN_TEST_GAME_SPLIT]\n",
    "        filtered_indices_of_low_activation = indices_of_low_activation[indices_of_low_activation[:, 0] < TRAIN_TEST_GAME_SPLIT]\n",
    "    else:\n",
    "        filtered_indices_of_high_activation = indices_of_high_activation[indices_of_high_activation[:, 0] >= TRAIN_TEST_GAME_SPLIT]\n",
    "        filtered_indices_of_low_activation = indices_of_low_activation[indices_of_low_activation[:, 0] >= TRAIN_TEST_GAME_SPLIT]\n",
    "    \n",
    "    high_activation_indices_for_feature = filtered_indices_of_high_activation[filtered_indices_of_high_activation[:, 2] == i]\n",
    "    low_activation_indices_for_feature = filtered_indices_of_low_activation[filtered_indices_of_low_activation[:, 2] == i]\n",
    "    low_activation_indices_for_feature = filtered_indices_of_low_activation[filtered_indices_of_low_activation[:, 1] > 100]\n",
    "    low_activation_indices_for_feature = low_activation_indices_for_feature[t.randint(0, len(low_activation_indices_for_feature), (low_to_high_data_points * len(high_activation_indices_for_feature), ))]\n",
    "    return high_activation_indices_for_feature, low_activation_indices_for_feature\n",
    "\n",
    "\n",
    "def get_counts(indices_for_feature, board_meets_criteria, use_train_data):\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    for game_index, position_index, _ in indices_for_feature:\n",
    "        if use_train_data == (game_index >= TRAIN_TEST_GAME_SPLIT):\n",
    "            continue\n",
    "        game_string = dataset['decoded_inputs'][game_index][:position_index]\n",
    "        last_space_index = get_last_space_index(game_string)\n",
    "        game_string = dataset['decoded_inputs'][game_index][:last_space_index]\n",
    "        board = chess_utils.pgn_string_to_board(game_string)\n",
    "        if board_meets_criteria(board):\n",
    "            positive_count += 1\n",
    "        else:\n",
    "            negative_count += 1\n",
    "    return positive_count, negative_count\n",
    "\n",
    "def evaluate_board_metric_criteria_for_feature(i, board_meets_criteria, use_train_data):\n",
    "    high_activation_indices_for_feature, low_activation_indices_for_feature = get_activation_data_for_feature(i, low_to_high_data_points, use_train_data)\n",
    "\n",
    "    true_positive_count, false_negative_count = get_counts(high_activation_indices_for_feature, board_meets_criteria, use_train_data)\n",
    "    false_positive_count, true_negative_count = get_counts(low_activation_indices_for_feature, board_meets_criteria, use_train_data)\n",
    "    return true_positive_count, false_negative_count, false_positive_count, true_negative_count\n",
    "    \n",
    "def get_summary_stats(true_positive_count, false_negative_count, false_positive_count, true_negative_count):\n",
    "    accuracy = (true_positive_count + true_negative_count) / (true_positive_count + true_negative_count + false_positive_count + false_negative_count)\n",
    "    precision = true_positive_count / (true_positive_count + false_positive_count)\n",
    "    recall = true_positive_count / (true_positive_count + false_negative_count)\n",
    "    f1_score = 2 * (precision * recall)/(precision + recall)\n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "true_positive_count, false_negative_count, false_positive_count, true_negative_count = evaluate_board_metric_criteria_for_feature(i, is_check, use_train_data=True)\n",
    "accuracy, precision, recall, f1_score = get_summary_stats(true_positive_count, false_negative_count, false_positive_count, true_negative_count)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to classify the feature using some simple hardcoded criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 attackers\n",
      "2 attackers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'is_check': Counter({True: 210}),\n",
       " 'piece_attacking_king': Counter({'n': 201, 'p': 6, 'q': 1, 'r': 1, 'b': 1}),\n",
       " 'location_of_piece_attacking_king': Counter({'g4': 23,\n",
       "          'd3': 20,\n",
       "          'c2': 18,\n",
       "          'e2': 18,\n",
       "          'f3': 17,\n",
       "          'f4': 13,\n",
       "          'e4': 13,\n",
       "          'f2': 13,\n",
       "          'e3': 10,\n",
       "          'g3': 7,\n",
       "          'h3': 7,\n",
       "          'd4': 5,\n",
       "          'c3': 5,\n",
       "          'c4': 5,\n",
       "          'f5': 4,\n",
       "          'e5': 3,\n",
       "          'h4': 3,\n",
       "          'd2': 3,\n",
       "          'g2': 3,\n",
       "          'a4': 2,\n",
       "          'a2': 2,\n",
       "          'b4': 2,\n",
       "          'a3': 2,\n",
       "          'b3': 2,\n",
       "          'a5': 2,\n",
       "          'f6': 1,\n",
       "          'e1': 1,\n",
       "          'd5': 1,\n",
       "          'b5': 1,\n",
       "          'f8': 1,\n",
       "          'h5': 1,\n",
       "          'c1': 1,\n",
       "          'g5': 1}),\n",
       " 'direction_of_attack': Counter({(1, -1): 132,\n",
       "          (-1, -1): 67,\n",
       "          (1, 1): 7,\n",
       "          (-1, 1): 2,\n",
       "          (-1, 0): 1,\n",
       "          (0, -1): 1}),\n",
       " 'count_attacking_pieces': Counter({1: 209, 2: 1}),\n",
       " 'relative_location_of_piece_attacking_king': Counter({(-1, 2): 73,\n",
       "          (-2, 1): 56,\n",
       "          (1, 2): 48,\n",
       "          (2, 1): 15,\n",
       "          (-2, -1): 7,\n",
       "          (1, 1): 4,\n",
       "          (-1, 1): 3,\n",
       "          (1, -2): 1,\n",
       "          (2, -1): 1,\n",
       "          (2, 0): 1,\n",
       "          (0, 6): 1})}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_into_three_categories(a, b):\n",
    "    if a < b:\n",
    "        return -1\n",
    "    else:\n",
    "        return int(a > b)\n",
    "\n",
    "def get_attacking_pieces_list(board):\n",
    "    return [board.piece_at(x).symbol() for x in board.attackers(not board.turn, board.king(board.turn))]\n",
    "\n",
    "def count_attacking_pieces(board):\n",
    "    return len(get_attacking_pieces_list(board))\n",
    "\n",
    "def piece_attacking_king(board):\n",
    "    output = get_attacking_pieces_list(board)\n",
    "    if len(output) > 1:\n",
    "        print(f\"{len(output)} attackers\")\n",
    "    if len(output) == 0:\n",
    "        print(\"No attackers\")\n",
    "        return None\n",
    "    return output[0]\n",
    "\n",
    "def location_of_piece_attacking_king(board):\n",
    "    output = [chess.square_name(x) for x in board.attackers(not board.turn, board.king(board.turn))]\n",
    "\n",
    "    if len(output) == 0:\n",
    "        print(\"No attackers\")\n",
    "        return None\n",
    "    return output[0]\n",
    "\n",
    "def relative_location_of_piece_attacking_king(board):\n",
    "    king_location = board.king(board.turn)\n",
    "    attacker_location = location_of_piece_attacking_king(board)\n",
    "    if attacker_location is None:\n",
    "        return None\n",
    "    king_file, king_rank = chess.square_file(king_location), chess.square_rank(king_location)\n",
    "    attacker_file, attacker_rank = chess.square_file(chess.parse_square(attacker_location)), chess.square_rank(chess.parse_square(attacker_location))\n",
    "    return attacker_file - king_file, attacker_rank - king_rank\n",
    "\n",
    "def direction_of_attack(board):\n",
    "    king_location = board.king(board.turn)\n",
    "    attacker = piece_attacking_king(board)\n",
    "    king_square = chess.square_name(king_location)\n",
    "    attacker_square = location_of_piece_attacking_king(board)\n",
    "    if attacker_square is None:\n",
    "        return None\n",
    "    index_1 = split_into_three_categories(king_square[0], attacker_square[0])\n",
    "    index_2 = split_into_three_categories(king_square[1], attacker_square[1])\n",
    "    if index_1 == index_2 == 0:\n",
    "        raise Exception(\"Index 1 and 2 are 0\")\n",
    "    return index_1, index_2\n",
    "\n",
    "def is_check(board):\n",
    "    return board.is_check()\n",
    "\n",
    "\n",
    "criteria_functions = [is_check, piece_attacking_king, location_of_piece_attacking_king, direction_of_attack, count_attacking_pieces, relative_location_of_piece_attacking_king]\n",
    "\n",
    "def collect_information_about_criteria(high_activation_indices, criteria_functions):\n",
    "    output_criteria_dict = {x.__name__: [] for x in criteria_functions}\n",
    "    for game_index, position_index, _ in high_activation_indices:\n",
    "        if game_index >= TRAIN_TEST_GAME_SPLIT:\n",
    "            continue\n",
    "        game_string = dataset['decoded_inputs'][game_index][:position_index]\n",
    "        last_space_index = get_last_space_index(game_string)\n",
    "        game_string = dataset['decoded_inputs'][game_index][:last_space_index]\n",
    "        board = chess_utils.pgn_string_to_board(game_string)\n",
    "        for criteria_function in criteria_functions:\n",
    "            output_criteria_dict[criteria_function.__name__].append(criteria_function(board))\n",
    "    for criterion in criteria_functions:\n",
    "        output_criteria_dict[criterion.__name__] = Counter(output_criteria_dict[criterion.__name__])\n",
    "    return output_criteria_dict\n",
    "\n",
    "collect_information_about_criteria(high_activation_indices_for_feature, criteria_functions)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game_string\n",
    "# board.piece_at(board.peek().to_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "2 attackers\n",
      "2 attackers\n",
      "10\n",
      "No attackers\n",
      "No attackers\n",
      "No attackers\n",
      "No attackers\n",
      "No attackers\n",
      "11\n",
      "12\n",
      "No attackers\n",
      "No attackers\n",
      "No attackers\n",
      "No attackers\n",
      "No attackers\n",
      "No attackers\n",
      "No attackers\n",
      "No attackers\n",
      "No attackers\n",
      "No attackers\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "2 attackers\n",
      "2 attackers\n",
      "2 attackers\n",
      "2 attackers\n",
      "2 attackers\n",
      "2 attackers\n",
      "2 attackers\n",
      "2 attackers\n",
      "2 attackers\n",
      "2 attackers\n",
      "17\n",
      "18\n",
      "19\n",
      "No attackers\n",
      "No attackers\n",
      "No attackers\n",
      "No attackers\n",
      "No attackers\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "2 attackers\n",
      "2 attackers\n"
     ]
    }
   ],
   "source": [
    "all_criteria_dicts = {}\n",
    "for i in range(len(features_for_check_state)):\n",
    "    print(i)\n",
    "    high_activation_indices_for_feature, low_activation_indices_for_feature = get_activation_data_for_feature(i, low_to_high_data_points)\n",
    "    all_criteria_dicts[i] = collect_information_about_criteria(high_activation_indices_for_feature, criteria_functions)\n",
    "    # true_positive_count, false_negative_count = get_counts(high_activation_indices_for_feature, board_meets_criteria)\n",
    "    # false_positive_count, true_negative_count = get_counts(low_activation_indices_for_feature, board_meets_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 3, 5, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 21, 22, 25, 26, 28, 29])\n"
     ]
    }
   ],
   "source": [
    "all_criteria_acceptable_keys_dict = {}\n",
    "threshold_for_including_key = 0.05\n",
    "threshold_for_including_feature = 0.5\n",
    "\n",
    "for i, criteria_dict in all_criteria_dicts.items():\n",
    "    criterion_acceptable_keys_dict = {}\n",
    "    for criterion, criterion_results_counter in criteria_dict.items():\n",
    "        counter_values = list(criterion_results_counter.values())\n",
    "        data_point_count = sum(counter_values)\n",
    "        if len(counter_values) == 0 or max(counter_values) < data_point_count * threshold_for_including_feature:\n",
    "            continue\n",
    "        acceptable_keys = [x for x in criterion_results_counter.keys() if criterion_results_counter[x]/data_point_count > threshold_for_including_key]\n",
    "        criterion_acceptable_keys_dict[criterion] = acceptable_keys\n",
    "    if len(criterion_acceptable_keys_dict) == 0:\n",
    "        continue\n",
    "    all_criteria_acceptable_keys_dict[i] = criterion_acceptable_keys_dict\n",
    "print(all_criteria_acceptable_keys_dict.keys())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Just using is check\n",
      "24 0 40 1160\n",
      "Precision: 0.375\n",
      "Using custom criteria\n",
      "24 0 22 1178\n",
      "Precision: 0.522\n",
      "1\n",
      "Just using is check\n",
      "128 0 168 6232\n",
      "Precision: 0.432\n",
      "Using custom criteria\n",
      "2 attackers\n",
      "126 2 63 6337\n",
      "Precision: 0.667\n",
      "3\n",
      "Just using is check\n",
      "31 0 43 1507\n",
      "Precision: 0.419\n",
      "Using custom criteria\n",
      "31 0 2 1548\n",
      "Precision: 0.939\n",
      "5\n",
      "Just using is check\n",
      "23 0 38 1112\n",
      "Precision: 0.377\n",
      "Using custom criteria\n",
      "19 4 1 1149\n",
      "Precision: 0.95\n",
      "8\n",
      "Just using is check\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid move: Bb4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/chessgpt_sae/chessgpt_sae/chess_utils.py:987\u001b[0m, in \u001b[0;36mpgn_string_to_board\u001b[0;34m(pgn_string, allow_exception)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 987\u001b[0m     \u001b[43mboard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_san\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmove\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/chessgpt/lib/python3.11/site-packages/chess/__init__.py:3105\u001b[0m, in \u001b[0;36mBoard.push_san\u001b[0;34m(self, san)\u001b[0m\n\u001b[1;32m   3092\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3093\u001b[0m \u001b[38;5;124;03mParses a move in standard algebraic notation, makes the move and puts\u001b[39;00m\n\u001b[1;32m   3094\u001b[0m \u001b[38;5;124;03mit onto the move stack.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3103\u001b[0m \u001b[38;5;124;03m    - :exc:`AmbiguousMoveError` if the SAN is ambiguous.\u001b[39;00m\n\u001b[1;32m   3104\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3105\u001b[0m move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_san\u001b[49m\u001b[43m(\u001b[49m\u001b[43msan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush(move)\n",
      "File \u001b[0;32m/opt/conda/envs/chessgpt/lib/python3.11/site-packages/chess/__init__.py:3077\u001b[0m, in \u001b[0;36mBoard.parse_san\u001b[0;34m(self, san)\u001b[0m\n\u001b[1;32m   3076\u001b[0m matched_move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3077\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmove\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_legal_moves\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrom_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmove\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpromotion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpromotion\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/chessgpt/lib/python3.11/site-packages/chess/__init__.py:3588\u001b[0m, in \u001b[0;36mBoard.generate_legal_moves\u001b[0;34m(self, from_mask, to_mask)\u001b[0m\n\u001b[1;32m   3587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m king_mask:\n\u001b[0;32m-> 3588\u001b[0m     king \u001b[38;5;241m=\u001b[39m \u001b[43mmsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mking_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3589\u001b[0m     blockers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slider_blockers(king)\n",
      "File \u001b[0;32m/opt/conda/envs/chessgpt/lib/python3.11/site-packages/chess/__init__.py:311\u001b[0m, in \u001b[0;36mmsb\u001b[0;34m(bb)\u001b[0m\n\u001b[1;32m    309\u001b[0m         bb \u001b[38;5;241m^\u001b[39m\u001b[38;5;241m=\u001b[39m r\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmsb\u001b[39m(bb: Bitboard) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bb\u001b[38;5;241m.\u001b[39mbit_length() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJust using is check\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m true_positive_count, false_negative_count, false_positive_count, true_negative_count \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_board_metric_criteria_for_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_train_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(true_positive_count, false_negative_count, false_positive_count, true_negative_count)\n\u001b[1;32m      6\u001b[0m accuracy, precision, recall, f1_score \u001b[38;5;241m=\u001b[39m get_summary_stats(true_positive_count, false_negative_count, false_positive_count, true_negative_count)\n",
      "Cell \u001b[0;32mIn[155], line 49\u001b[0m, in \u001b[0;36mevaluate_board_metric_criteria_for_feature\u001b[0;34m(i, board_meets_criteria, use_train_data)\u001b[0m\n\u001b[1;32m     46\u001b[0m high_activation_indices_for_feature, low_activation_indices_for_feature \u001b[38;5;241m=\u001b[39m get_activation_data_for_feature(i, low_to_high_data_points, use_train_data)\n\u001b[1;32m     48\u001b[0m true_positive_count, false_negative_count \u001b[38;5;241m=\u001b[39m get_counts(high_activation_indices_for_feature, board_meets_criteria, use_train_data)\n\u001b[0;32m---> 49\u001b[0m false_positive_count, true_negative_count \u001b[38;5;241m=\u001b[39m \u001b[43mget_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlow_activation_indices_for_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboard_meets_criteria\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_train_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m true_positive_count, false_negative_count, false_positive_count, true_negative_count\n",
      "Cell \u001b[0;32mIn[155], line 38\u001b[0m, in \u001b[0;36mget_counts\u001b[0;34m(indices_for_feature, board_meets_criteria, use_train_data)\u001b[0m\n\u001b[1;32m     36\u001b[0m last_space_index \u001b[38;5;241m=\u001b[39m get_last_space_index(game_string)\n\u001b[1;32m     37\u001b[0m game_string \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoded_inputs\u001b[39m\u001b[38;5;124m'\u001b[39m][game_index][:last_space_index]\n\u001b[0;32m---> 38\u001b[0m board \u001b[38;5;241m=\u001b[39m \u001b[43mchess_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpgn_string_to_board\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m board_meets_criteria(board):\n\u001b[1;32m     40\u001b[0m     positive_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/chessgpt_sae/chessgpt_sae/chess_utils.py:992\u001b[0m, in \u001b[0;36mpgn_string_to_board\u001b[0;34m(pgn_string, allow_exception)\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 992\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid move: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmove\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m board\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid move: Bb4"
     ]
    }
   ],
   "source": [
    "for i in all_criteria_acceptable_keys_dict.keys():\n",
    "    print(i)\n",
    "    print(\"Just using is check\")\n",
    "    true_positive_count, false_negative_count, false_positive_count, true_negative_count = evaluate_board_metric_criteria_for_feature(i, is_check, use_train_data=False)\n",
    "    print(true_positive_count, false_negative_count, false_positive_count, true_negative_count)\n",
    "    accuracy, precision, recall, f1_score = get_summary_stats(true_positive_count, false_negative_count, false_positive_count, true_negative_count)\n",
    "    # print(f\"Accuracy: {round(accuracy, 3)}\")\n",
    "    print(f\"Precision: {round(precision, 3)}\")\n",
    "    # print(f\"Recall: {round(recall, 3)}\")\n",
    "    # print(f\"F1 Score: {round(f1_score, 3)}\")\n",
    "\n",
    "    custom_criteria_dict = all_criteria_acceptable_keys_dict[i]\n",
    "    def custom_criteria(board):\n",
    "        for criterion_function in criteria_functions:\n",
    "            if criterion_function.__name__ not in custom_criteria_dict:\n",
    "                continue\n",
    "            criterion_value = criterion_function(board)\n",
    "            if criterion_value not in custom_criteria_dict[criterion_function.__name__]:\n",
    "                return False\n",
    "        return True\n",
    "    print(\"Using custom criteria\")\n",
    "    true_positive_count, false_negative_count, false_positive_count, true_negative_count = evaluate_board_metric_criteria_for_feature(i, custom_criteria, use_train_data=False)\n",
    "    print(true_positive_count, false_negative_count, false_positive_count, true_negative_count)\n",
    "    accuracy, precision, recall, f1_score = get_summary_stats(true_positive_count, false_negative_count, false_positive_count, true_negative_count)\n",
    "    # print(f\"Accuracy: {round(accuracy, 3)   }\")\n",
    "    print(f\"Precision: {round(precision, 3)}\")\n",
    "    # print(f\"Recall: {round(recall, 3)}\")\n",
    "    # print(f\"F1 Score: {round(f1_score, 3)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'relative_location_of_piece_attacking_king'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chessgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
